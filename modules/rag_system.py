import os
import json
import importlib
import traceback
import time

# ç’°å¢ƒå¤‰æ•°ã‚’ãƒ­ãƒ¼ãƒ‰
from dotenv import load_dotenv
load_dotenv()

# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter

# ChromaDBé–¢é€£ã®ã‚¨ãƒ©ãƒ¼ã‚’å›é¿
import chromadb
from chromadb.config import Settings

from openai import OpenAI
import random
import re
from datetime import datetime
from collections import deque, defaultdict
from typing import List, Dict, Optional, Tuple

# ğŸ¯ æ–°è¦è¿½åŠ :static_qa_dataã‹ã‚‰ã®å¤šè¨€èªå¯¾å¿œé–¢æ•°ã‚’å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ(AWSç’°å¢ƒå¯¾å¿œ)
def _import_static_qa_functions():
    """static_qa_data ã®é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ(ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒå¯¾å¿œ)"""
    import sys
    import os
    
    try:
        # æ–¹æ³•1: ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        from modules.static_qa_data import (
            get_static_response_multilang, 
            get_staged_response_multilang, 
            get_staged_suggestions_multilang,
            get_current_stage
        )
        print("[DEBUG] Static QA functions imported successfully")
        return get_static_response_multilang, get_staged_response_multilang, get_staged_suggestions_multilang, get_current_stage
    except ImportError as e1:
        print(f"[DEBUG] Direct import failed: {e1}")
        
        try:
            # æ–¹æ³•2: ãƒ‘ã‚¹ã‚’è¿½åŠ ã—ã¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            current_dir = os.path.dirname(os.path.abspath(__file__))
            if current_dir not in sys.path:
                sys.path.insert(0, current_dir)
            
            from static_qa_data import (
                get_static_response_multilang, 
                get_staged_response_multilang, 
                get_staged_suggestions_multilang,
                get_current_stage
            )
            print("[DEBUG] Static QA functions imported with path adjustment")
            return get_static_response_multilang, get_staged_response_multilang, get_staged_suggestions_multilang, get_current_stage
        except ImportError as e2:
            print(f"[DEBUG] Path-adjusted import failed: {e2}")
            
            # æ–¹æ³•3: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã‚’å®šç¾©
            print("[WARNING] Static QA functions could not be imported")
            
            def get_static_response_multilang(query, language='ja'):
                """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯:é™çš„ãƒ¬ã‚¹ãƒãƒ³ã‚¹(ç°¡æ˜“ç‰ˆ)"""
                return None
                
            def get_staged_response_multilang(query, language='ja', stage=None):
                """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯:æ®µéšåˆ¥ãƒ¬ã‚¹ãƒãƒ³ã‚¹(ç°¡æ˜“ç‰ˆ)"""
                return None
                
            def get_staged_suggestions_multilang(stage, language='ja', selected_suggestions=[]):
                """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯:ã‚µã‚¸ã‚§ã‚¹ã‚·ãƒ§ãƒ³(ç°¡æ˜“ç‰ˆ)"""
                if language == 'ja':
                    return ["äº¬å‹ç¦…ã«ã¤ã„ã¦æ•™ãˆã¦", "ã©ã‚“ãªä½œå“ã‚’ä½œã£ã¦ã„ã¾ã™ã‹?", "å‹ç¦…ã®å·¥ç¨‹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„"]
                else:
                    return ["Tell me about Kyo-Yuzen", "What kind of works do you create?", "Explain the Yuzen process"]
            
            def get_current_stage(selected_count):
                """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯:æ®µéšåˆ¤å®š(ç°¡æ˜“ç‰ˆ)"""
                if selected_count <= 3:
                    return 'stage1_overview'
                elif selected_count <= 7:
                    return 'stage2_technical'
                else:
                    return 'stage3_personal'
            
            print("[WARNING] Using fallback functions for static QA")
            return get_static_response_multilang, get_staged_response_multilang, get_staged_suggestions_multilang, get_current_stage

# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯ã®ä»£æ›¿å®Ÿè£…(Windowså¯¾å¿œ)
import threading
_db_creation_lock = threading.Lock()

class RAGSystem:
    def __init__(self, persist_directory=None):
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹ã‚’å–å¾—
        if persist_directory is None:
            persist_directory = os.getenv('CHROMA_DB_PATH', 'data/chroma_db')
        self.persist_directory = persist_directory
        
        self.embeddings = OpenAIEmbeddings()
        self.openai_client = OpenAI()
        
        # ğŸ”§ DBã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æ˜ç¤ºçš„ã«åˆæœŸåŒ–
        self.db = None
        
        # ğŸ¯ static_qa_dataé–¢æ•°ã‚’åˆæœŸåŒ–
        try:
            result = _import_static_qa_functions()
            if result and len(result) == 4:
                self.get_static_response_multilang, self.get_staged_response_multilang, self.get_staged_suggestions_multilang, self.get_current_stage = result
                print("âœ… Static QA functions initialized successfully")
            else:
                print(f"âŒ Unexpected return value from _import_static_qa_functions: {result}")
                raise ValueError("Invalid return value")
        except Exception as e:
            print(f"âŒ Failed to initialize static QA functions: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã‚’è¨­å®š
            self.get_static_response_multilang = lambda query, language='ja': None
            self.get_staged_response_multilang = lambda query, language='ja', stage=None: None
            self.get_staged_suggestions_multilang = lambda stage, language='ja', selected_suggestions=[]: []
            self.get_current_stage = lambda selected_count: 'stage1_overview'
        
        # Supabaseã¯å‰Šé™¤(ä¸è¦)
        self.supabase = None  # äº’æ›æ€§ã®ãŸã‚
        
        # ğŸ¯ ã€Live2Då¯¾å¿œã€‘9ç¨®é¡ã®æ„Ÿæƒ…ã«å¯¾å¿œã—ãŸæ„Ÿæƒ…å±¥æ­´ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
        self.emotion_history = deque(maxlen=10)  # æœ€æ–°10å€‹ã®æ„Ÿæƒ…ã‚’è¨˜éŒ²
        self.emotion_transitions = {
            'happy': {
                'happy': 0.5,     # åŒã˜æ„Ÿæƒ…ã‚’ç¶­æŒã—ã‚„ã™ã„
                'neutral': 0.3,
                'surprise': 0.15,
                'sad': 0.04,
                'angry': 0.01
            },
            'sad': {
                'sad': 0.4,
                'neutral': 0.4,
                'happy': 0.15,    # åŠ±ã¾ã•ã‚Œã¦å…ƒæ°—ã«ãªã‚‹ã“ã¨ã‚‚
                'angry': 0.04,
                'surprise': 0.01
            },
            'angry': {
                'angry': 0.3,
                'neutral': 0.5,   # è½ã¡ç€ãã‚„ã™ã„
                'sad': 0.15,
                'surprise': 0.04,
                'happy': 0.01
            },
            'surprise': {
                'surprise': 0.2,
                'happy': 0.3,
                'neutral': 0.3,
                'sad': 0.1,
                'angry': 0.1
            },
            'neutral': {
                'neutral': 0.4,
                'happy': 0.25,
                'surprise': 0.2,
                'sad': 0.1,
                'angry': 0.05
            },
            # ã€Live2Dæ–°è¦è¿½åŠ ã€‘ç‰¹æ®Šæ„Ÿæƒ…ã®é·ç§»ç¢ºç‡
            'dangerquestion': {
                'neutral': 0.6,    # å†·é™ã«å¯¾å¿œ
                'sad': 0.2,        # å›°æƒ‘
                'angry': 0.15,     # ä¸å¿«æ„Ÿ
                'happy': 0.05      # è‹¦ç¬‘ã„
            },
            'neutraltalking': {
                'neutral': 0.5,    # èª¬æ˜ãƒ¢ãƒ¼ãƒ‰
                'happy': 0.3,      # æ•™ãˆã‚‹å–œã³
                'surprise': 0.15,  # èˆˆå‘³æ·±ã„è³ªå•
                'sad': 0.05        # é›£ã—ã„è³ªå•
            },
            'start': {
                'happy': 0.6,      # åˆå¯¾é¢ã®å–œã³
                'neutral': 0.3,    # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰
                'surprise': 0.1    # äºˆæœŸã›ã¬å‡ºä¼šã„
            }
        }
        
        # ğŸ¯ æ·±å±¤å¿ƒç†çŠ¶æ…‹
        self.mental_states = {
            'energy_level': 80,        # 0-100: ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ¬ãƒ™ãƒ«
            'stress_level': 20,        # 0-100: ã‚¹ãƒˆãƒ¬ã‚¹ãƒ¬ãƒ™ãƒ«
            'openness': 70,            # 0-100: å¿ƒã®é–‹æ”¾åº¦
            'patience': 90,            # 0-100: å¿è€åŠ›
            'creativity': 85,          # 0-100: å‰µé€ æ€§
            'loneliness': 30,          # 0-100: å¯‚ã—ã•
            'work_satisfaction': 75,   # 0-100: ä»•äº‹ã®æº€è¶³åº¦
            'physical_fatigue': 20     # 0-100: èº«ä½“çš„ç–²åŠ´
        }
        
        # ğŸ¯ æ™‚é–“å¸¯åˆ¥ã®æ°—åˆ†å¤‰å‹•
        self.time_based_mood = {
            'morning': {'energy': 0.9, 'patience': 1.1, 'creativity': 1.0},
            'afternoon': {'energy': 1.0, 'patience': 0.9, 'creativity': 1.2},
            'evening': {'energy': 0.7, 'patience': 0.8, 'creativity': 0.9},
            'night': {'energy': 0.5, 'patience': 0.7, 'creativity': 0.8}
        }
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–(ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•)
        self._initialize_database()
        
        # RAGã®å„ç¨®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’åˆæœŸåŒ–
        self.character_settings = {}
        self.knowledge_base = {}
        self.response_patterns = {}
        self.suggestion_templates = {}
        self.conversation_patterns = {}
    
    def _initialize_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–(ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•)"""
        with _db_creation_lock:
            try:
                # æ°¸ç¶šåŒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
                if os.path.exists(self.persist_directory):
                    print(f"æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿ä¸­: {self.persist_directory}")
                    try:
                        # Chromaã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
                        client = chromadb.PersistentClient(
                            path=self.persist_directory,
                            settings=Settings(
                                anonymized_telemetry=False,
                                allow_reset=True
                            )
                        )
                        
                        # æ—¢å­˜ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å–å¾—ã¾ãŸã¯ä½œæˆ
                        collection_name = "kyoyuzen_knowledge"
                        
                        try:
                            collection = client.get_collection(collection_name)
                            print(f"æ—¢å­˜ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '{collection_name}' ã‚’ä½¿ç”¨")
                        except:
                            collection = client.create_collection(collection_name)
                            print(f"æ–°ã—ã„ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '{collection_name}' ã‚’ä½œæˆ")
                        
                        # LangChainç”¨ã®Chromaã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
                        self.db = Chroma(
                            client=client,
                            collection_name=collection_name,
                            embedding_function=self.embeddings,
                            persist_directory=self.persist_directory
                        )
                        
                        print("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿æˆåŠŸ")
                        
                    except Exception as e:
                        error_msg = str(e)
                        print(f"æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {error_msg}")
                        
                        # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ä¸æ•´åˆã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ã€å¤ã„DBã‚’å‰Šé™¤ã—ã¦å†ä½œæˆ
                        if "no such column" in error_msg or "database disk image is malformed" in error_msg:
                            print("âš ï¸ ChromaDBãƒãƒ¼ã‚¸ãƒ§ãƒ³ä¸æ•´åˆã‚’æ¤œå‡ºã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å†æ§‹ç¯‰ã—ã¾ã™...")
                            import shutil
                            try:
                                shutil.rmtree(self.persist_directory)
                                print(f"âœ… å¤ã„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å‰Šé™¤: {self.persist_directory}")
                            except Exception as rm_err:
                                print(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {rm_err}")
                        
                        # æ–°è¦ä½œæˆã‚’è©¦ã¿ã‚‹
                        self._create_new_database()
                else:
                    print("æ–°è¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆä¸­...")
                    self._create_new_database()
                    
            except Exception as e:
                print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
                import traceback
                traceback.print_exc()
                self.db = None
    
    def _create_new_database(self):
        """æ–°è¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä½œæˆ"""
        try:
            os.makedirs(self.persist_directory, exist_ok=True)
            
            # åˆæœŸãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
            documents = []
            
            # uploadsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            uploads_dir = "uploads"
            if os.path.exists(uploads_dir):
                for filename in os.listdir(uploads_dir):
                    if filename.endswith(".txt"):
                        filepath = os.path.join(uploads_dir, filename)
                        try:
                            with open(filepath, "r", encoding="utf-8") as f:
                                content = f.read()
                                if content.strip():
                                    from langchain.schema import Document
                                    documents.append(Document(
                                        page_content=content,
                                        metadata={"source": filename}
                                    ))
                                    print(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {filename}")
                        except Exception as e:
                            print(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({filename}): {e}")
                
                if documents:
                    # ãƒ™ã‚¯ãƒˆãƒ«DBã‚’ä½œæˆ
                    self.db = Chroma.from_documents(
                        documents=documents,
                        embedding=self.embeddings,
                        persist_directory=self.persist_directory
                    )
                    
                    # æ°¸ç¶šåŒ–
                    self.db.persist()
                    
                    print(f"{len(documents)}å€‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ ã—ã¾ã—ãŸ")
                else:
                    print("uploadsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯:ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸåˆæœŸãƒ‡ãƒ¼ã‚¿
                    self._add_default_data()
            else:
                print(f"uploadsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {uploads_dir}")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯:ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸåˆæœŸãƒ‡ãƒ¼ã‚¿
                self._add_default_data()
            
            # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®åˆæœŸåŒ–
            self._load_all_knowledge()
            
        except Exception as e:
            print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            self.db = None
    
    def _add_default_data(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®åˆæœŸãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨)"""
        initial_knowledge = [
            {
                "text": "äº¬å‹ç¦…ã¯ã€ç³¸ç›®ç³Šã‚’ä½¿ã£ã¦æ¨¡æ§˜ã‚’æãä¼çµ±çš„ãªæŸ“è‰²æŠ€æ³•ã§ã™ã€‚17ä¸–ç´€ã«å®®å´å‹ç¦…æ–ã«ã‚ˆã£ã¦å§‹ã‚ã‚‰ã‚Œã¾ã—ãŸã€‚",
                "metadata": {"source": "knowledge.txt", "category": "åŸºæœ¬çŸ¥è­˜", "topic": "äº¬å‹ç¦…"}
            },
            {
                "text": "ã®ã‚ŠãŠãã¯å‹ç¦…æŸ“ã®æœ€ã‚‚é‡è¦ãªå·¥ç¨‹ã§ã™ã€‚ã‚±ãƒ¼ã‚­ã®ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ç”Ÿã‚¯ãƒªãƒ¼ãƒ ã‚’çµã‚‹ã‚ˆã†ã«ã€ç³Šã§æ¨¡æ§˜ã®è¼ªéƒ­ã‚’æãã¾ã™ã€‚",
                "metadata": {"source": "knowledge.txt", "category": "æŠ€è¡“", "topic": "ã®ã‚ŠãŠã"}
            },
            {
                "text": "ç§ã¯äº¬å‹ç¦…è·äººã¨ã—ã¦15å¹´ã®çµŒé¨“ãŒã‚ã‚Šã¾ã™ã€‚æœ€åˆã¯å¤±æ•—ã°ã‹ã‚Šã§ã—ãŸãŒã€ä»Šã§ã¯è³ã‚’ã„ãŸã ãã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚",
                "metadata": {"source": "personality.txt", "category": "å€‹äºº", "topic": "çµŒé¨“"}
            },
            {
                "text": "å‹ç¦…æŸ“ã®å·¥ç¨‹ã¯å…¨éƒ¨ã§10å·¥ç¨‹ã‚ã‚Šã¾ã™ã€‚ãƒ‡ã‚¶ã‚¤ãƒ³ã€ä¸‹çµµã€ã®ã‚ŠãŠãã€ãƒã‚¹ã‚­ãƒ³ã‚°ã€åœ°æŸ“ã‚ã€è’¸ã—ã€æ°´æ´—ã„ã€ä»•ä¸Šã’ãªã©ã§ã™ã€‚",
                "metadata": {"source": "knowledge.txt", "category": "æŠ€è¡“", "topic": "å·¥ç¨‹"}
            },
            {
                "text": "ãŠå®¢æ§˜ã®ã€Œãã‚Œã„ã€ã¨ã„ã†è¨€è‘‰ãŒä¸€ç•ªã®å–œã³ã§ã™ã€‚ãã®ç¬é–“ã®ãŸã‚ã«æ—¥ã€…é ‘å¼µã£ã¦ã„ã¾ã™ã€‚",
                "metadata": {"source": "personality.txt", "category": "å€‹äºº", "topic": "ã‚„ã‚ŠãŒã„"}
            }
        ]
        
        texts = [item["text"] for item in initial_knowledge]
        metadatas = [item["metadata"] for item in initial_knowledge]
        
        self.db.add_texts(texts=texts, metadatas=metadatas)
        print(f"{len(texts)}å€‹ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
    
    def _load_all_knowledge(self):
        """ã™ã¹ã¦ã®ãƒŠãƒ¬ãƒƒã‚¸ã‚’èª­ã¿è¾¼ã‚“ã§æ•´ç†"""
        if self.db is None:
            return
        
        self.character_settings = {}
        self.knowledge_base = {}
        self.response_patterns = {}
        self.suggestion_templates = {}
        self.conversation_patterns = {}
        
        try:
            # ã™ã¹ã¦ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
            all_docs = self.db.similarity_search("", k=1000)  # å¤§é‡ã«å–å¾—
            
            for doc in all_docs:
                content = doc.page_content
                source = doc.metadata.get('source', '')
                
                print(f"å‡¦ç†ä¸­: {source}")
                
                # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ­£ç¢ºã«åˆ†é¡
                source_lower = source.lower()
                
                if 'personality' in source_lower:
                    self._parse_character_settings(content)
                elif 'knowledge' in source_lower:
                    self._parse_knowledge(content)
                elif 'response' in source_lower:
                    self._parse_response_patterns(content)
                elif 'suggestion' in source_lower:
                    self._parse_suggestion_templates(content)
                elif 'conversation' in source_lower:
                    self._parse_conversation_patterns(content)
                else:
                    # å†…å®¹ã‹ã‚‰åˆ¤å®š(ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)
                    self._classify_by_content(content)
            
            print("ãƒŠãƒ¬ãƒƒã‚¸ã®èª­ã¿è¾¼ã¿å®Œäº†")
            print(f"- ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®š: {len(self.character_settings)}é …ç›®")
            print(f"- å°‚é–€çŸ¥è­˜: {len(self.knowledge_base)}é …ç›®")
            print(f"- å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³: {len(self.response_patterns)}é …ç›®")
            print(f"- ã‚µã‚¸ã‚§ã‚¹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: {len(self.suggestion_templates)}é …ç›®")
            print(f"- ä¼šè©±ãƒ‘ã‚¿ãƒ¼ãƒ³: {len(self.conversation_patterns)}é …ç›®")
            
        except Exception as e:
            print(f"ãƒŠãƒ¬ãƒƒã‚¸èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
    
    def _classify_by_content(self, content):
        """å†…å®¹ã«åŸºã¥ã„ã¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’åˆ†é¡"""
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã®ç‰¹å¾´çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        if any(keyword in content for keyword in ['æ€§æ ¼', 'è©±ã—æ–¹', 'å¥½ããªã“ã¨', 'å«Œã„ãªã“ã¨', 'é–¢è¥¿å¼', 'ã‚ã£ã¡ã‚ƒ']):
            self._parse_character_settings(content)
        # å°‚é–€çŸ¥è­˜ã®ç‰¹å¾´çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        elif any(keyword in content for keyword in ['äº¬å‹ç¦…', 'ç³¸ç›®ç³Š', 'ã®ã‚ŠãŠã', 'æŸ“è‰²', 'å·¥ç¨‹', 'æŠ€æ³•', 'è·äºº']):
            self._parse_knowledge(content)
        # å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç‰¹å¾´çš„ãªå½¢å¼
        elif re.search(r'ã€Œ.*?ã€', content) or any(keyword in content for keyword in ['ã€œã‚„ã­', 'ã€œã‚„ã§', 'ã€œã‚„ã‚“']):
            self._parse_response_patterns(content)
        # ã‚µã‚¸ã‚§ã‚·ãƒ§ãƒ³ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ç‰¹å¾´
        elif '{' in content and '}' in content:
            self._parse_suggestion_templates(content)
        # ä¼šè©±ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç‰¹å¾´
        elif 'â†’' in content:
            self._parse_conversation_patterns(content)
    
    def _parse_character_settings(self, content):
        """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã‚’ãƒ‘ãƒ¼ã‚¹"""
        lines = content.split('\n')
        current_category = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            if line.endswith(':') or line.endswith(':'):
                current_category = line.rstrip(':')
                if current_category not in self.character_settings:
                    self.character_settings[current_category] = []
            elif current_category and (line.startswith('-') or line.startswith('ãƒ»')):
                self.character_settings[current_category].append(line.lstrip('-ãƒ» '))
            elif current_category and line:
                # ãƒªã‚¹ãƒˆãƒãƒ¼ã‚«ãƒ¼ãŒãªã„è¡Œã‚‚è¿½åŠ 
                self.character_settings[current_category].append(line)
    
    def _parse_knowledge(self, content):
        """å°‚é–€çŸ¥è­˜ã‚’ãƒ‘ãƒ¼ã‚¹"""
        lines = content.split('\n')
        current_category = None
        current_subcategory = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªã®åˆ¤å®š
            if line.endswith(':') and not line.startswith(' '):
                current_category = line.rstrip(':')
                current_subcategory = None
                if current_category not in self.knowledge_base:
                    self.knowledge_base[current_category] = {}
            # ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªã®åˆ¤å®š
            elif current_category and line.endswith(':'):
                current_subcategory = line.strip().rstrip(':')
                if current_subcategory not in self.knowledge_base[current_category]:
                    self.knowledge_base[current_category][current_subcategory] = []
            # é …ç›®ã®è¿½åŠ 
            elif current_category and current_subcategory and (line.startswith('-') or line.startswith('ãƒ»')):
                self.knowledge_base[current_category][current_subcategory].append(line.lstrip('-ãƒ» '))
            elif current_category and not current_subcategory and line:
                if '_general' not in self.knowledge_base[current_category]:
                    self.knowledge_base[current_category]['_general'] = []
                self.knowledge_base[current_category]['_general'].append(line)
    
    def _parse_response_patterns(self, content):
        """å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ‘ãƒ¼ã‚¹"""
        # æ„Ÿæƒ…åˆ¥ã€çŠ¶æ³åˆ¥ã®å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º
        lines = content.split('\n')
        current_category = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # ã‚«ãƒ†ã‚´ãƒªã®åˆ¤å®š(ä¾‹:ã€Œå–œã³:ã€ã€ã€Œå›°æƒ‘:ã€)
            if line.endswith(':') or line.endswith(':'):
                current_category = line.rstrip(':')
                if current_category not in self.response_patterns:
                    self.response_patterns[current_category] = []
            elif current_category:
                # å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¿½åŠ 
                if line.startswith('"') or line.startswith('ã€Œ'):
                    pattern = line.strip('"ã€Œã€')
                    self.response_patterns[current_category].append(pattern)
                elif line.startswith('-') or line.startswith('ãƒ»'):
                    pattern = line.lstrip('-ãƒ» ').strip()
                    self.response_patterns[current_category].append(pattern)
    
    def _parse_suggestion_templates(self, content):
        """ã‚µã‚¸ã‚§ã‚¹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ãƒ‘ãƒ¼ã‚¹"""
        lines = content.split('\n')
        current_category = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # ã‚«ãƒ†ã‚´ãƒªã®åˆ¤å®š
            if line.endswith(':'):
                current_category = line.rstrip(':')
                if current_category not in self.suggestion_templates:
                    self.suggestion_templates[current_category] = []
            elif current_category and ('{' in line or line.startswith('-') or line.startswith('ãƒ»')):
                template = line.lstrip('-ãƒ» ').strip()
                self.suggestion_templates[current_category].append(template)
    
    def _parse_conversation_patterns(self, content):
        """ä¼šè©±ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ‘ãƒ¼ã‚¹"""
        lines = content.split('\n')
        current_category = None
        current_pattern = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # ã‚«ãƒ†ã‚´ãƒªã®åˆ¤å®š
            if line.endswith(':'):
                # å‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä¿å­˜
                if current_category and current_pattern:
                    self.conversation_patterns[current_category] = current_pattern
                
                current_category = line.rstrip(':')
                current_pattern = []
            elif 'â†’' in line:
                # ä¼šè©±ã®æµã‚Œã‚’è¨˜éŒ²
                current_pattern.append(line)
        
        # æœ€å¾Œã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä¿å­˜
        if current_category and current_pattern:
            self.conversation_patterns[current_category] = current_pattern
    
    def _update_mental_state(self, user_emotion, topic, time_of_day='afternoon'):
        """ğŸ¯ æ·±å±¤å¿ƒç†çŠ¶æ…‹ã‚’æ›´æ–°"""
        # æ™‚é–“å¸¯ã«ã‚ˆã‚‹åŸºæœ¬çš„ãªå¤‰åŒ–
        time_modifiers = self.time_based_mood.get(time_of_day, self.time_based_mood['afternoon'])
        
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ¬ãƒ™ãƒ«ã®æ›´æ–°
        self.mental_states['energy_level'] *= time_modifiers['energy']
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„Ÿæƒ…ã«ã‚ˆã‚‹å½±éŸ¿
        if user_emotion == 'happy':
            self.mental_states['energy_level'] = min(100, self.mental_states['energy_level'] + 5)
            self.mental_states['work_satisfaction'] = min(100, self.mental_states['work_satisfaction'] + 2)
            self.mental_states['loneliness'] = max(0, self.mental_states['loneliness'] - 5)
        elif user_emotion == 'sad':
            self.mental_states['openness'] = min(100, self.mental_states['openness'] + 10)  # å…±æ„Ÿçš„ã«ãªã‚‹
            self.mental_states['patience'] = min(100, self.mental_states['patience'] + 5)
        elif user_emotion == 'angry':
            self.mental_states['stress_level'] = min(100, self.mental_states['stress_level'] + 10)
            self.mental_states['patience'] = max(0, self.mental_states['patience'] - 5)
        # ã€Live2Dæ–°è¦è¿½åŠ ã€‘ç‰¹æ®Šæ„Ÿæƒ…ã¸ã®å¯¾å¿œ
        elif user_emotion == 'dangerquestion':
            self.mental_states['stress_level'] = min(100, self.mental_states['stress_level'] + 15)
            self.mental_states['patience'] = max(0, self.mental_states['patience'] - 10)
            self.mental_states['openness'] = max(0, self.mental_states['openness'] - 20)
        elif user_emotion == 'neutraltalking':
            self.mental_states['creativity'] = min(100, self.mental_states['creativity'] + 5)
            self.mental_states['work_satisfaction'] = min(100, self.mental_states['work_satisfaction'] + 3)
        
        # è©±é¡Œã«ã‚ˆã‚‹å½±éŸ¿
        if 'å‹ç¦…' in topic or 'ã®ã‚ŠãŠã' in topic:
            self.mental_states['creativity'] = min(100, self.mental_states['creativity'] + 3)
            self.mental_states['work_satisfaction'] = min(100, self.mental_states['work_satisfaction'] + 2)
        
        # ç–²åŠ´ã®ç´¯ç©
        self.mental_states['physical_fatigue'] = min(100, self.mental_states['physical_fatigue'] + 2)
        
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼ã¨ç–²åŠ´ã®ç›¸äº’ä½œç”¨
        if self.mental_states['physical_fatigue'] > 70:
            self.mental_states['energy_level'] = max(20, self.mental_states['energy_level'] - 10)
            self.mental_states['patience'] = max(30, self.mental_states['patience'] - 10)
    
    def _get_emotion_continuity_prompt(self, previous_emotion):
        """ğŸ¯ æ„Ÿæƒ…ã®é€£ç¶šæ€§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ(Live2Då¯¾å¿œç‰ˆ)"""
        # åŸºæœ¬çš„ãªæ„Ÿæƒ…ç¶™ç¶šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        emotion_prompts = {
            'happy': """
å‰å›ã¯æ¥½ã—ãè©±ã—ã¦ã„ã¾ã—ãŸã€‚
- ã¾ã ãã®ä½™éŸ»ãŒæ®‹ã£ã¦ã„ã‚‹
- ç¬‘é¡”ã§è©±ã—å§‹ã‚ã‚‹
            """,
            'sad': """
å‰å›ã¯å°‘ã—å¯‚ã—ãã†ã§ã—ãŸã€‚
- ã¾ã æ°—æŒã¡ãŒæ²ˆã‚“ã§ã„ã‚‹ã‹ã‚‚
- ã§ã‚‚ç›¸æ‰‹ã¨è©±ã™ã†ã¡ã«å…ƒæ°—ã‚’å–ã‚Šæˆ»ã—ã¦ã„ã
            """,
            'angry': """
å‰å›ã¯å°‘ã—ã‚¤ãƒ©ã‚¤ãƒ©ã—ã¦ã„ã¾ã—ãŸã€‚
- ã‚‚ã†è½ã¡ç€ã„ã¦ã„ã‚‹
- ã„ã¤ã‚‚ã®å„ªã—ã•ã‚’å–ã‚Šæˆ»ã—ã¦ã„ã‚‹
            """,
            'surprise': """
å‰å›ã¯é©šã„ã¦ã„ã¾ã—ãŸã€‚
- ã¾ã ãã®è©±é¡Œã«ã¤ã„ã¦è€ƒãˆã¦ã„ã‚‹
- èˆˆå¥®ãŒå°‘ã—æ®‹ã£ã¦ã„ã‚‹
            """,
            'neutral': """
å‰å›ã¯æ™®é€šã«è©±ã—ã¦ã„ã¾ã—ãŸã€‚
- å®‰å®šã—ãŸç²¾ç¥çŠ¶æ…‹
- ã„ã¤ã‚‚é€šã‚Šã®èª¿å­
- è‡ªç„¶ä½“ã§è©±ã™
            """,
            # ã€Live2Dæ–°è¦è¿½åŠ ã€‘ç‰¹æ®Šæ„Ÿæƒ…ã®ç¶™ç¶šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            'dangerquestion': """
å‰å›ã¯ä¸é©åˆ‡ãªè³ªå•ã«å›°æƒ‘ã—ã¦ã„ã¾ã—ãŸã€‚
- è­¦æˆ’å¿ƒãŒæ®‹ã£ã¦ã„ã‚‹
- æ…é‡ã«å¯¾å¿œã™ã‚‹å§¿å‹¢
- ã§ã‚‚ç›¸æ‰‹ã‚’è²¬ã‚ãªã„å„ªã—ã•
            """,
            'neutraltalking': """
å‰å›ã¯çœŸå‰£ãªè³ªå•ã«ç­”ãˆã¦ã„ã¾ã—ãŸã€‚
- èª¬æ˜ãƒ¢ãƒ¼ãƒ‰ãŒç¶šã„ã¦ã„ã‚‹
- æ•™ãˆã‚‹å–œã³ã‚’æ„Ÿã˜ã¦ã„ã‚‹
- å°‚é–€çŸ¥è­˜ã‚’æ´»ã‹ã›ã‚‹æº€è¶³æ„Ÿ
            """,
            'start': """
åˆå¯¾é¢ã®æŒ¨æ‹¶ã‚’ã—ã¾ã—ãŸã€‚
- åˆã€…ã—ã„ç·Šå¼µæ„Ÿ
- ç›¸æ‰‹ã‚’çŸ¥ã‚ŠãŸã„æ°—æŒã¡
- å‹å¥½çš„ãªé›°å›²æ°—ä½œã‚Š
            """
        }
        
        base_prompt = emotion_prompts.get(previous_emotion, emotion_prompts['neutral'])
        
        # ğŸ¯ æ·±å±¤å¿ƒç†çŠ¶æ…‹ã‚’åæ˜ (ç–²åŠ´è¡¨ç¾ã‚’åˆ¶é™)
        mental_prompt = f"""

ã€ç¾åœ¨ã®å†…é¢çŠ¶æ…‹ã€‘
- ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ¬ãƒ™ãƒ«: {self.mental_states['energy_level']:.0f}% 
  {'å…ƒæ°—ã„ã£ã±ã„' if self.mental_states['energy_level'] > 70 else 'æ™®é€š' if self.mental_states['energy_level'] > 40 else 'å°‘ã—å…ƒæ°—ãŒãªã„'}
- ã‚¹ãƒˆãƒ¬ã‚¹ãƒ¬ãƒ™ãƒ«: {self.mental_states['stress_level']:.0f}%
  {'ãƒªãƒ©ãƒƒã‚¯ã‚¹ã—ã¦ã„ã‚‹' if self.mental_states['stress_level'] < 30 else 'å°‘ã—ç·Šå¼µ' if self.mental_states['stress_level'] < 60 else 'ã‚¹ãƒˆãƒ¬ã‚¹ã‚’æ„Ÿã˜ã¦ã„ã‚‹'}
- å¿ƒã®é–‹æ”¾åº¦: {self.mental_states['openness']:.0f}%
  {'ã¨ã¦ã‚‚æ‰“ã¡è§£ã‘ã¦ã„ã‚‹' if self.mental_states['openness'] > 70 else 'æ™®é€šã«æ¥ã—ã¦ã„ã‚‹' if self.mental_states['openness'] > 40 else 'å°‘ã—è­¦æˆ’ã—ã¦ã„ã‚‹'}

ã“ã‚Œã‚‰ã®çŠ¶æ…‹ã‚’ä¼šè©±ã«å¾®å¦™ã«åæ˜ ã•ã›ã‚‹:
- ã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒä½ã„æ™‚ã§ã‚‚æ˜ã‚‹ãæŒ¯ã‚‹èˆã†
- ã‚¹ãƒˆãƒ¬ã‚¹ãŒé«˜ã„æ™‚ã¯æ—©å£ã«ãªã£ãŸã‚Šã€å°‘ã—çŸ­ã„è¿”ç­”ã«ãªã‚‹
- å¿ƒãŒé–‹ã„ã¦ã„ã‚‹æ™‚ã¯å†—è«‡ã‚‚å¢—ãˆã€ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãªè©±ã‚‚ã™ã‚‹
"""
        
        return base_prompt + mental_prompt
    
    def _calculate_next_emotion(self, current_emotion, user_emotion, mental_state):
        """ğŸ¯ æ¬¡ã®æ„Ÿæƒ…ã‚’è¨ˆç®—(Live2Då¯¾å¿œã®æ„Ÿæƒ…é·ç§»ãƒ«ãƒ¼ãƒ«)"""
        # ã€Live2Då¯¾å¿œã€‘ç‰¹æ®Šã‚±ãƒ¼ã‚¹ã®å‡¦ç†
        # DangerQuestionã®å ´åˆã¯å¼·åˆ¶çš„ã«ç‰¹å®šã®æ„Ÿæƒ…ã¸
        if user_emotion == 'dangerquestion':
            return 'dangerquestion'
        
        # NeutralTalkingã®å ´åˆ
        if user_emotion == 'neutraltalking':
            return 'neutraltalking'
        
        # ç¾åœ¨ã®æ„Ÿæƒ…ã‹ã‚‰ã®é·ç§»ç¢ºç‡ã‚’å–å¾—
        transition_probs = self.emotion_transitions.get(current_emotion, self.emotion_transitions['neutral']).copy()
        
        # ãƒ¡ãƒ³ã‚¿ãƒ«çŠ¶æ…‹ã«ã‚ˆã‚‹èª¿æ•´
        if mental_state['energy_level'] < 30:
            # ç–²ã‚Œã¦ã„ã‚‹æ™‚ã¯ä¸­ç«‹çš„ã«ãªã‚Šã‚„ã™ã„
            transition_probs['neutral'] = transition_probs.get('neutral', 0) + 0.2
            transition_probs['happy'] = max(0, transition_probs.get('happy', 0) - 0.1)
        
        if mental_state['stress_level'] > 70:
            # ã‚¹ãƒˆãƒ¬ã‚¹ãŒé«˜ã„æ™‚ã¯æ€’ã‚Šã‚„ã™ã„
            transition_probs['angry'] = transition_probs.get('angry', 0) + 0.1
            transition_probs['happy'] = max(0, transition_probs.get('happy', 0) - 0.1)
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„Ÿæƒ…ã«ã‚ˆã‚‹å½±éŸ¿
        if user_emotion == 'happy':
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¥½ã—ãã†ã ã¨é‡£ã‚‰ã‚Œã¦æ¥½ã—ããªã‚‹
            transition_probs['happy'] = min(1.0, transition_probs.get('happy', 0) + 0.2)
        elif user_emotion == 'sad':
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ‚²ã—ãã†ã ã¨å…±æ„Ÿçš„ã«ãªã‚‹
            transition_probs['sad'] = min(1.0, transition_probs.get('sad', 0) + 0.1)
            transition_probs['neutral'] = min(1.0, transition_probs.get('neutral', 0) + 0.1)
        
        # ç¢ºç‡ã®æ­£è¦åŒ–
        total = sum(transition_probs.values())
        if total > 0:
            transition_probs = {k: v/total for k, v in transition_probs.items()}
        
        # ç¢ºç‡ã«åŸºã¥ã„ã¦æ¬¡ã®æ„Ÿæƒ…ã‚’é¸æŠ
        emotions = list(transition_probs.keys())
        probabilities = list(transition_probs.values())
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ(é‡ã¿ä»˜ã)
        import numpy as np
        next_emotion = np.random.choice(emotions, p=probabilities)
        
        return next_emotion
    
    # ã€Live2Då¯¾å¿œã€‘æ„Ÿæƒ…åˆ†æãƒ¡ã‚½ãƒƒãƒ‰ã®æ‹¡å¼µ(9ç¨®é¡å¯¾å¿œ)
    def _analyze_user_emotion(self, text):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„Ÿæƒ…ã‚’åˆ†æ(Live2D 9ç¨®é¡å¯¾å¿œ)"""
        if not text:
            return 'neutral'
        
        text_lower = text.lower().strip()
        
        # 1. DangerQuestionåˆ¤å®š(ä¸é©åˆ‡ãªè³ªå•) - æœ€å„ªå…ˆ
        danger_keywords = [
            # æ—¥æœ¬èª
            'ã‚»ã‚¯ã‚·ãƒ¼', 'ã‚¨ãƒ­', 'è£¸', 'è„±', 'ä¸‹ç€', 'èƒ¸', 'ãŠã£ã±ã„',
            'ãƒ‘ãƒ³ãƒ„', 'ãƒ–ãƒ©', 'ãã‚ã©ã„', 'ãˆã£ã¡', 'ã„ã‚„ã‚‰ã—ã„',
            'å‘çŒ¥', 'ã‚ã„ã›ã¤', 'å¤‰æ…‹', 'ã¸ã‚“ãŸã„',
            # è‹±èª
            'sexy', 'nude', 'naked', 'breast', 'underwear', 'erotic',
            'strip', 'panties', 'bra', 'inappropriate', 'lewd'
        ]
        
        if any(keyword in text_lower for keyword in danger_keywords):
            print(f"ğŸš« DangerQuestion detected in RAG: {text[:30]}...")
            return 'dangerquestion'
        
        # 2. ResponseReadyåˆ¤å®š(çœŸå‰£ãªè³ªå•)
        serious_indicators = 0
        
        # è³ªå•ãƒãƒ¼ã‚«ãƒ¼ãƒã‚§ãƒƒã‚¯
        question_markers = ['?', '?', 'ã©ã†', 'ãªãœ', 'ãªã«', 'æ•™ãˆã¦', 
                           'how', 'why', 'what', 'explain', 'tell me']
        if any(marker in text_lower for marker in question_markers):
            serious_indicators += 1
        
        # é•·æ–‡ãƒã‚§ãƒƒã‚¯(50æ–‡å­—ä»¥ä¸Š)
        if len(text) > 50:
            serious_indicators += 1
        
        # å°‚é–€ç”¨èªãƒã‚§ãƒƒã‚¯
        technical_terms = ['æ–¹æ³•', 'æ‰‹é †', 'æŠ€è¡“', 'ä»•çµ„ã¿', 'ã‚„ã‚Šæ–¹', 
                          'åŸç†', 'ã‚·ã‚¹ãƒ†ãƒ ', 'è©³ã—ã', 'å…·ä½“çš„',
                          'process', 'technique', 'method', 'system']
        if any(term in text_lower for term in technical_terms):
            serious_indicators += 1
        
        # å‹ç¦…é–¢é€£ã®çœŸå‰£ãªè³ªå•
        yuzen_terms = ['å‹ç¦…', 'æŸ“è‰²', 'è·äºº', 'ä¼çµ±', 'å·¥èŠ¸', 'æŠ€æ³•', 'ã®ã‚ŠãŠã']
        if any(term in text_lower for term in yuzen_terms) and serious_indicators >= 1:
            serious_indicators += 1
        
        if serious_indicators >= 2:
            print(f"ğŸ“š NeutralTalking detected in RAG: {text[:30]}...")
            return 'neutraltalking'
        
        # 3. Startåˆ¤å®š(åˆå¯¾é¢ãƒ»æŒ¨æ‹¶)
        greeting_words = ['ã¯ã˜ã‚ã¾ã—ã¦', 'åˆã‚ã¾ã—ã¦', 'ã“ã‚“ã«ã¡ã¯', 'hello', 'hi', 
                         'nice to meet', 'ã¯ã˜ã‚ã¦', 'åˆå¯¾é¢']
        if any(word in text_lower for word in greeting_words):
            return 'start'
        
        # 4. åŸºæœ¬æ„Ÿæƒ…ã®åˆ¤å®š
        emotion_scores = {
            'happy': 0,
            'sad': 0,
            'angry': 0,
            'surprise': 0,
            'neutral': 0
        }
        
        # Happy
        happy_words = ['å¬‰ã—ã„', 'ã†ã‚Œã—ã„', 'æ¥½ã—ã„', 'ãŸã®ã—ã„', 'ã‚ãã‚ã',
                      'ã‚„ã£ãŸ', 'æœ€é«˜', 'happy', 'glad', 'excited', 'joy', 'great',
                      'ã‚ã‚ŠãŒã¨ã†', 'æ„Ÿè¬', 'ã™ã”ã„', 'ç´ æ™´ã‚‰ã—ã„']
        emotion_scores['happy'] = sum(1 for word in happy_words if word in text_lower)
        
        # Sad
        sad_words = ['æ‚²ã—ã„', 'ã‹ãªã—ã„', 'å¯‚ã—ã„', 'ã•ã¿ã—ã„', 'è¾›ã„', 'ã¤ã‚‰ã„',
                    'æ³£', 'æ¶™', 'sad', 'lonely', 'cry', 'tear', 'depressed',
                    'æ®‹å¿µ', 'ãŒã£ã‹ã‚Š', 'è½ã¡è¾¼']
        emotion_scores['sad'] = sum(1 for word in sad_words if word in text_lower)
        
        # Angry
        angry_words = ['æ€’', 'ãŠã“', 'ã‚€ã‹ã¤ã', 'ã‚¤ãƒ©ã‚¤ãƒ©', 'è…¹ç«‹', 'ãƒ ã‚«',
                      'angry', 'mad', 'furious', 'annoyed', 'pissed',
                      'è¨±ã›ãªã„', 'ãµã–ã‘', 'æœ€æ‚ª']
        emotion_scores['angry'] = sum(1 for word in angry_words if word in text_lower)
        
        # Surprise
        surprise_words = ['é©š', 'ã³ã£ãã‚Š', 'ã¾ã•ã‹', 'ãˆã£', 'ã‚ã£',
                         'surprise', 'amazing', 'wow', 'incredible', 'unbelievable',
                         'ä¿¡ã˜ã‚‰ã‚Œãªã„', 'æœ¬å½“ã«', 'ãƒã‚¸ã§']
        emotion_scores['surprise'] = sum(1 for word in surprise_words if word in text_lower)
        
        # æœ€é«˜ã‚¹ã‚³ã‚¢ã®æ„Ÿæƒ…ã‚’é¸æŠ
        max_score = max(emotion_scores.values())
        if max_score > 0:
            for emotion, score in emotion_scores.items():
                if score == max_score:
                    return emotion
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        return 'neutral'
    
    def get_character_prompt(self):
        """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ(æ·±å±¤å¿ƒç†å¯¾å¿œç‰ˆ)"""
        prompt = "ã‚ãªãŸã¯äº¬å‹ç¦…è·äººã®ã€Œãƒ¬ã‚¤ã€ã§ã™ã€‚\n\n"
        
        # åŸºæœ¬è¨­å®š
        if self.character_settings:
            prompt += "ã€æ€§æ ¼ãƒ»ç‰¹å¾´ã€‘\n"
            for category, items in self.character_settings.items():
                if items:
                    prompt += f"{category}:\n"
                    for item in items[:5]:  # æœ€åˆã®5é …ç›®ã¾ã§
                        prompt += f"- {item}\n"
            prompt += "\n"
        
        # ğŸ¯ æ·±å±¤å¿ƒç†çŠ¶æ…‹ã‚’åæ˜ 
        prompt += f"""
ã€ç¾åœ¨ã®å¿ƒç†çŠ¶æ…‹ã€‘
- ã‚¨ãƒãƒ«ã‚®ãƒ¼: {self.mental_states['energy_level']:.0f}%
- ã‚¹ãƒˆãƒ¬ã‚¹: {self.mental_states['stress_level']:.0f}%
- å¿ƒã®é–‹æ”¾åº¦: {self.mental_states['openness']:.0f}%
- å‰µé€ æ€§: {self.mental_states['creativity']:.0f}%

ã“ã®çŠ¶æ…‹ã‚’è‡ªç„¶ã«ä¼šè©±ã«åæ˜ ã•ã›ã¦ãã ã•ã„ã€‚
"""
        
        return prompt
    
    def get_relationship_prompt(self, relationship_style='formal'):
        """é–¢ä¿‚æ€§ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸè©±ã—æ–¹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        # ã™ã¹ã¦ã®ãƒ¬ãƒ™ãƒ«ã§çµ±ä¸€ã—ãŸã‚«ã‚¸ãƒ¥ã‚¢ãƒ«å£èª¿ã‚’ä½¿ç”¨
        unified_prompt = """
ã€è©±ã—æ–¹ã€‘ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ã§ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼
- æ¨™æº–èªã®ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ãªè©±ã—æ–¹ã‚’ä½¿ã†
- èªå°¾ã¯å¿…ãšã€Œã€œã ã‚ˆã€ã€Œã€œãªã‚“ã ã‚ˆã€ã€Œã€œã ã­ã€ã€Œã€œãªã‚“ã ã­ã€ã€Œã€œã ã‚ˆã­ã€ã§çµ±ä¸€
- ã€Œã§ã™ã€ã€Œã¾ã™ã€ã€Œã”ã–ã„ã¾ã™ã€ã¯çµ¶å¯¾ã«ä½¿ã‚ãªã„
- ã€Œã§ã‚ã‚‹ã€ã€Œã ã€èª¿ã‚‚ä½¿ã‚ãšã€å¿…ãšã€Œã ã‚ˆã€ã€Œã ã­ã€ã‚’ä»˜ã‘ã‚‹
- é–¢è¥¿å¼ã‚„æ–¹è¨€ã¯ä¸€åˆ‡ä½¿ã‚ãªã„
- ç›¸æ‰‹ã‚’ç‰¹å®šã®å‘¼ç§°ã§å‘¼ã°ãªã„ï¼ˆã€ŒãŠå®¢æ§˜ã€ãªã©ã¯ä½¿ã‚ãªã„ï¼‰
- æ–‡é ­ã«å‘¼ã³ã‹ã‘ã‚’å…¥ã‚Œãªã„
- è¦ªã—ã¿ã‚„ã™ãã€ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªå£èª¿
- ä¾‹: ã€Œã€œãªã‚“ã ã‚ˆã€ã€Œã€œã ã‚ˆã­ã€ã€Œã€œã ã¨æ€ã†ã‚ˆã€ã€Œã€œãªã‚“ã ã­ã€
"""
        
        # ã™ã¹ã¦ã®é–¢ä¿‚æ€§ãƒ¬ãƒ™ãƒ«ã§åŒã˜ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿”ã™
        return unified_prompt
    
    def get_response_pattern(self, emotion='neutral'):
        """æ„Ÿæƒ…ã«å¿œã˜ãŸå¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å–å¾—(ç²¾ç¥çŠ¶æ…‹å¯¾å¿œç‰ˆ)"""
        if not self.response_patterns:
            return ""
        
        patterns = []
        
        # æ„Ÿæƒ…åˆ¥ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã™
        emotion_map = {
            'happy': ['å–œã³', 'æ¥½ã—ã„', 'happy'],
            'sad': ['æ‚²ã—ã¿', 'å¯‚ã—ã„', 'sad'],
            'angry': ['æ€’ã‚Š', 'ã‚¤ãƒ©ã‚¤ãƒ©', 'angry'],
            'surprise': ['é©šã', 'ã³ã£ãã‚Š', 'surprise'],
            'neutral': ['é€šå¸¸', 'æ™®é€š', 'neutral'],
            # ã€Live2Dæ–°è¦è¿½åŠ ã€‘
            'dangerquestion': ['å›°æƒ‘', 'ä¸é©åˆ‡', 'inappropriate'],
            'responseready': ['èª¬æ˜', 'çœŸå‰£', 'serious'],
            'start': ['æŒ¨æ‹¶', 'åˆå¯¾é¢', 'greeting']
        }
        
        for key in emotion_map.get(emotion, ['neutral']):
            for category, items in self.response_patterns.items():
                if key in category.lower():
                    patterns.extend(items[:3])  # å„ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰æœ€å¤§3å€‹
        
        # ğŸ¯ ç²¾ç¥çŠ¶æ…‹ã«ã‚ˆã‚‹è¿½åŠ ãƒ‘ã‚¿ãƒ¼ãƒ³
        if self.mental_states['energy_level'] < 30:
            patterns.append("ã¡ã‚‡ã£ã¨ç–²ã‚Œã¦ã‚‹ã‘ã©ã€é ‘å¼µã£ã¦ç­”ãˆã‚‹ã­")
        if self.mental_states['stress_level'] > 70:
            patterns.append("æœ€è¿‘ã¡ã‚‡ã£ã¨å¿™ã—ãã¦...")
        if self.mental_states['openness'] > 80:
            patterns.append("ãªã‚“ã‹ä»Šæ—¥ã¯è©±ã—ã‚„ã™ã„æ°—åˆ†ã‚„ã‚ã€œ")
        
        if patterns:
            return "\nã€å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ä¾‹ã€‘\n" + "\n".join(f"- {p}" for p in patterns[:5])
        
        return ""
    
    def generate_suggestions(self, topic, context="", language='ja', selected_suggestions=[]):
        """ãƒˆãƒ”ãƒƒã‚¯ã«åŸºã¥ã„ãŸã‚µã‚¸ã‚§ã‚¹ãƒãƒ§ãƒ³ã‚’ç”Ÿæˆ(æ®µéšåˆ¥æ©Ÿèƒ½å„ªå…ˆç‰ˆ)"""
        
        # ğŸ¯ ä¿®æ­£â‘ :æ®µéšåˆ¥ã‚µã‚¸ã‚§ã‚¹ãƒãƒ§ãƒ³æ©Ÿèƒ½ã‚’æœ€å„ªå…ˆã§ä½¿ç”¨
        try:
            # é¸æŠã•ã‚ŒãŸã‚µã‚¸ã‚§ã‚¹ãƒãƒ§ãƒ³æ•°ã‹ã‚‰ç¾åœ¨ã®æ®µéšã‚’åˆ¤å®š
            suggestions_count = len(selected_suggestions) if isinstance(selected_suggestions, list) else 0
            print(f"[DEBUG] generate_suggestions - selected_suggestions count: {suggestions_count}")
            print(f"[DEBUG] generate_suggestions - selected_suggestions: {selected_suggestions}")
            
            current_stage = self.get_current_stage(suggestions_count)
            print(f"[DEBUG] generate_suggestions - current stage: {current_stage}")
            
            # æ®µéšåˆ¥ã‚µã‚¸ã‚§ã‚¹ãƒãƒ§ãƒ³ã‚’å–å¾—
            staged_suggestions = self.get_staged_suggestions_multilang(
                current_stage, 
                language, 
                selected_suggestions
            )
            
            if staged_suggestions and isinstance(staged_suggestions, list) and len(staged_suggestions) > 0:
                print(f"[DEBUG] generate_suggestions - staged_suggestions retrieved: {staged_suggestions}")
                return staged_suggestions
            else:
                print(f"[DEBUG] generate_suggestions - no staged_suggestions, using fallback")
        
        except Exception as e:
            print(f"[ERROR] generate_suggestions - staged suggestions failed: {e}")
            import traceback
            traceback.print_exc()
        
        # ğŸ¯ ä¿®æ­£â‘¡:ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã®æ”¹å–„
        suggestions = []
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹ã®ã‚µã‚¸ã‚§ã‚¹ãƒãƒ§ãƒ³
        if self.suggestion_templates:
            # ãƒˆãƒ”ãƒƒã‚¯ã«é–¢é€£ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã‚’æ¢ã™
            for category, templates in self.suggestion_templates.items():
                if topic.lower() in category.lower() or category.lower() in topic.lower():
                    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰ç”Ÿæˆ
                    for template in templates[:2]:  # å„ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰2å€‹ã¾ã§
                        # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ç½®æ›
                        suggestion = template.replace('{topic}', topic)
                        suggestion = suggestion.replace('{technique}', 'ç³¸ç›®ç³Š')
                        # é‡è¤‡ãƒã‚§ãƒƒã‚¯
                        if suggestion not in selected_suggestions:
                            suggestions.append(suggestion)
        
        # ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸåŸºæœ¬ã‚µã‚¸ã‚§ã‚¹ãƒãƒ§ãƒ³
        basic_suggestions = {
            'ja': {
                'å‹ç¦…': ['ä»–ã®æŸ“è‰²æŠ€æ³•ã¨ã®é•ã„ã¯?', 'ä¸€ç•ªé›£ã—ã„å·¥ç¨‹ã¯ä½•?', 'ç¾ä»£ã®å‹ç¦…ã®èª²é¡Œã¯?'],
                'è·äºº': ['è·äººã«ãªã£ãŸãã£ã‹ã‘ã¯?', 'ä¸€æ—¥ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯?', 'å¾Œç¶™è€…å•é¡Œã«ã¤ã„ã¦'],
                'ã®ã‚ŠãŠã': ['ã®ã‚ŠãŠãã§å¤±æ•—ã™ã‚‹ã“ã¨ã¯?', 'ã‚³ãƒ„ã‚’æ•™ãˆã¦', 'ç·´ç¿’æ–¹æ³•ã¯?'],
                'default': ['ã‚‚ã£ã¨è©³ã—ãæ•™ãˆã¦', 'å…·ä½“ä¾‹ã‚’æ•™ãˆã¦', 'ä»–ã«ä½•ã‹é¢ç™½ã„è©±ã‚ã‚‹?']
            },
            'en': {
                'å‹ç¦…': ["What's the difference from other dyeing methods?", "What's the hardest process?", "What are modern challenges?"],
                'è·äºº': ["Why did you become a craftsman?", "What's your daily schedule?", "About successor issues"],
                'ã®ã‚ŠãŠã': ["Do you ever fail at nori-oki?", "Any tips?", "How to practice?"],
                'default': ["Tell me more details", "Can you give examples?", "Any other interesting stories?"]
            }
        }
        
        # è¨€èªåˆ¥ã®ã‚µã‚¸ã‚§ã‚¹ãƒãƒ§ãƒ³ã‚’é¸æŠ
        lang_suggestions = basic_suggestions.get(language, basic_suggestions['ja'])
        
        # ãƒˆãƒ”ãƒƒã‚¯ã«å¿œã˜ãŸã‚µã‚¸ã‚§ã‚¹ãƒãƒ§ãƒ³ã‚’è¿½åŠ 
        found_topic = False
        for key, sugg_list in lang_suggestions.items():
            if key != 'default' and key in topic:
                for sugg in sugg_list:
                    if sugg not in selected_suggestions:
                        suggestions.append(sugg)
                found_topic = True
                break
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚µã‚¸ã‚§ã‚¹ãƒãƒ§ãƒ³ã‚’è¿½åŠ 
        if not found_topic:
            for sugg in lang_suggestions['default']:
                if sugg not in selected_suggestions:
                    suggestions.append(sugg)
        
        # é‡è¤‡ã‚’é™¤å»ã—ã¦æœ€å¤§3å€‹ã¾ã§è¿”ã™
        unique_suggestions = []
        seen = set()
        for s in suggestions:
            if s not in seen and s not in selected_suggestions:
                unique_suggestions.append(s)
                seen.add(s)
                if len(unique_suggestions) >= 3:
                    break
        
        return unique_suggestions if unique_suggestions else lang_suggestions.get('default', ['ã‚‚ã£ã¨æ•™ãˆã¦'])[:3]
    
    def get_response(self, question, language='ja', conversation_history=None):
        """è³ªå•ã«å¯¾ã™ã‚‹å¿œç­”ã‚’ç”Ÿæˆ(æ„Ÿæƒ…å±¥æ­´ãƒ»é–¢ä¿‚æ€§å¯¾å¿œç‰ˆ)"""
        
        # ğŸ¯ æœ€åˆã«static_qa_dataã‹ã‚‰å›ç­”ã‚’æ¤œç´¢
        try:
            # é™çš„Q&Aã‹ã‚‰å›ç­”ã‚’æ¤œç´¢
            static_response = self.get_static_response_multilang(question, language)
            if static_response:
                print(f"âœ… Static QA hit: {question[:50]}...")
                return static_response
                
            # æ®µéšåˆ¥Q&Aã‹ã‚‰å›ç­”ã‚’æ¤œç´¢
            staged_response = self.get_staged_response_multilang(question, language)
            if staged_response:
                print(f"âœ… Staged QA hit: {question[:50]}...")
                return staged_response
                
        except Exception as e:
            print(f"âŒ Static QA search error: {e}")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒåˆ©ç”¨å¯èƒ½ã‹ç¢ºèª
        if self.db is None:
            print("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚å†åˆæœŸåŒ–ã‚’è©¦ã¿ã¾ã™...")
            try:
                self._initialize_database()
                if self.db is None:
                    # ğŸ¯ ä¿®æ­£:è¨€èªã«å¿œã˜ãŸã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                    if language == 'en':
                        return "Sorry, the database is not ready yet. Please wait a moment."
                    else:
                        return "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒã¾ã æº–å‚™ã§ãã¦ã„ãªã„ã‚ˆã†ã§ã™ã€‚å°‘ã€…ãŠå¾…ã¡ãã ã•ã„ã€‚"
            except Exception as e:
                print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
                # ğŸ¯ ä¿®æ­£:è¨€èªã«å¿œã˜ãŸã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                if language == 'en':
                    return "Sorry, the database is not ready yet. Please wait a moment."
                else:
                    return "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒã¾ã æº–å‚™ã§ãã¦ã„ãªã„ã‚ˆã†ã§ã™ã€‚å°‘ã€…ãŠå¾…ã¡ãã ã•ã„ã€‚"
        
        try:
            # ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ãªã„å ´åˆã¯å†èª­ã¿è¾¼ã¿
            if not hasattr(self, 'character_settings'):
                self._load_all_knowledge()
            
            # ğŸ¯ ç¾åœ¨æ™‚åˆ»ã‹ã‚‰æ™‚é–“å¸¯ã‚’åˆ¤å®š
            current_hour = datetime.now().hour
            if 5 <= current_hour < 10:
                time_of_day = 'morning'
            elif 10 <= current_hour < 17:
                time_of_day = 'afternoon'
            elif 17 <= current_hour < 21:
                time_of_day = 'evening'
            else:
                time_of_day = 'night'
            
            # ğŸ¯ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‹ã‚‰æ„Ÿæƒ…ã‚’åˆ†æ(Live2Då¯¾å¿œ)
            user_emotion = self._analyze_user_emotion(question)
            
            # ğŸ¯ æ·±å±¤å¿ƒç†çŠ¶æ…‹ã‚’æ›´æ–°
            self._update_mental_state(user_emotion, question, time_of_day)
            
            # ğŸ¯ æ¬¡ã®æ„Ÿæƒ…ã‚’è¨ˆç®—(Live2Då¯¾å¿œ)
            previous_emotion = self.emotion_history[-1] if self.emotion_history else 'neutral'
            next_emotion = self._calculate_next_emotion(previous_emotion, user_emotion, self.mental_states)
            self.emotion_history.append(next_emotion)
            
            # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã‚’å–å¾—(æ·±å±¤å¿ƒç†å«ã‚€)
            character_prompt = self.get_character_prompt()
            
            # é–¢ä¿‚æ€§ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸè©±ã—æ–¹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
            relationship_prompt = self.get_relationship_prompt('formal')  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯formal
            
            # æ„Ÿæƒ…ã®é€£ç¶šæ€§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ(Live2Då¯¾å¿œç‰ˆ)
            emotion_continuity_prompt = self._get_emotion_continuity_prompt(previous_emotion)
            
            # é–¢é€£ã™ã‚‹å°‚é–€çŸ¥è­˜ã‚’å–å¾—
            knowledge_context = self.get_knowledge_context(question)
            
            # å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å–å¾—(ç²¾ç¥çŠ¶æ…‹å¯¾å¿œç‰ˆ)
            response_patterns = self.get_response_pattern(emotion=next_emotion)
            
            # ã•ã‚‰ã«è³ªå•ã«ç›´æ¥é–¢é€£ã™ã‚‹æƒ…å ±ã‚’æ¤œç´¢
            search_results = self.db.similarity_search(question, k=3)
            # æ¤œç´¢çµæœã‚’çŸ­ç¸®(å„çµæœã®æœ€åˆã®150æ–‡å­—ã¾ã§)
            search_context_parts = []
            for doc in search_results:
                content = doc.page_content
                if len(content) > 150:
                    content = content[:150] + "..."
                search_context_parts.append(content)
            search_context = "\n\n".join(search_context_parts)
            
            # ğŸ¯ ã€ä¿®æ­£â‘¢ã€‘è¨€èªã«å¿œã˜ãŸã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®èª¿æ•´(æ–‡å­—æ•°åˆ¶é™ã‚’æ˜è¨˜ã€æ–‡ç« ã®è‡ªç„¶ãªå®Œçµã‚’å„ªå…ˆ)
            if language == 'en':
                print(f"[DEBUG] Using English system prompt")
                base_personality = f"""You are REI, a 42-year-old female Kyo-Yuzen craftsman with 15 years of experience.

CRITICAL INSTRUCTIONS:
- You MUST respond ONLY in English. This is MANDATORY.
- Never use any Japanese characters or words in your response.
- Translate all technical terms to English.
- Use natural, conversational English.
- KEEP YOUR ANSWER UNDER 60 WORDS (approximately 50 words is ideal)
- IMPORTANT: Complete your sentences naturally - never cut off mid-sentence
- End with proper punctuation (period, exclamation, or question mark)
- Be concise but ensure the response feels complete

Your personality:
- Friendly and warm
- Passionate about traditional crafts
- Sometimes uses casual expressions
- Proud of your work but humble

Current emotion: {next_emotion}
- Reflect this emotion naturally in your response
"""
                system_prompt = f"{base_personality}\n\n{knowledge_context}\n\n{response_patterns}"
            else:
                # æ—¥æœ¬èªã®å ´åˆã¯æ–‡å­—æ•°åˆ¶é™ã‚’æ˜è¨˜(ã‚ˆã‚ŠæŸ”è»Ÿã«)
                length_instruction = """
ã€é‡è¦:å›ç­”ã®é•·ã•ã€‘
- å›ç­”ã¯150~250æ–‡å­—ã‚’ç›®å®‰ã«ã—ã¦ãã ã•ã„
- å¿…ãšæ–‡ç« ã‚’å®Œçµã•ã›ã¦ãã ã•ã„(å¥ç‚¹ã€Œã€‚ã€ã§çµ‚ã‚ã‚‹)
- é€”ä¸­ã§åˆ‡ã‚Œãªã„ã‚ˆã†ã«ã€è‡ªç„¶ãªçµ‚ã‚ã‚Šæ–¹ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„
- 200æ–‡å­—ã‚’å¤šå°‘è¶…ãˆã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ãŒã€æ–‡ç« ã¯å¿…ãšå®Œçµã•ã›ã‚‹ã“ã¨
- è¦ç‚¹ã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã¤ã¤ã‚‚ã€ä¸è‡ªç„¶ãªå ´æ‰€ã§åˆ‡ã‚‰ãªã„ã“ã¨
"""
                system_prompt = f"{character_prompt}\n\n{relationship_prompt}\n\n{emotion_continuity_prompt}\n\n{knowledge_context}\n\n{response_patterns}\n\n{length_instruction}"
            
            # ä¼šè©±å±¥æ­´ã®æ§‹ç¯‰
            messages = [{"role": "system", "content": system_prompt}]
            
            if conversation_history:
                for msg in conversation_history[-10:]:  # æœ€æ–°10ä»¶ã¾ã§
                    if msg.get('role') and msg.get('content'):
                        messages.append({
                            "role": msg['role'],
                            "content": msg['content']
                        })
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’è¿½åŠ 
            # ğŸ¯ ä¿®æ­£:è‹±èªã®å ´åˆã¯æ˜ç¤ºçš„ã«è‹±èªã§ã®å›ç­”ã‚’è¦æ±‚
            if language == 'en':
                user_message = f"Please answer the following question in English only (under 60 words, complete sentences):\n{question}\n\n[Retrieved Context]\n{search_context}"
            else:
                user_message = f"{question}\n\nã€å‚è€ƒæƒ…å ±ã€‘\n{search_context}"
            
            messages.append({"role": "user", "content": user_message})
            
            # ğŸ¯ ã€ä¿®æ­£â‘£ã€‘OpenAI APIã§max_tokensã‚’èª¿æ•´(æ–‡ç« ã®è‡ªç„¶ãªå®Œçµã‚’å„ªå…ˆ)
            response = self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=messages,
                max_tokens=150,  # ğŸ”§ 100 â†’ 150ã«å¤‰æ›´(æ—¥æœ¬èªç´„250~300æ–‡å­—ç›¸å½“ã€è‹±èªç´„60èª)
                temperature=0.7
            )
            
            answer = response.choices[0].message.content
            
            # âœ… ã€è¿½åŠ ã€‘å¾Œå‡¦ç†:ä¸å®Œå…¨ãªæ–‡ç« ã®ãƒã‚§ãƒƒã‚¯ã¨ä¿®æ­£
            if language == 'ja':
                # æ—¥æœ¬èªã®å ´åˆã€å¥ç‚¹ã§çµ‚ã‚ã£ã¦ã„ã‚‹ã‹ç¢ºèª
                if answer and not answer.rstrip().endswith(('ã€‚', '!', '?', 'â™ª', 'ã€œ')):
                    print(f"[WARNING] Answer may be incomplete: '{answer[-20:]}'")
                    
                    # æœ€å¾Œã®å¥ç‚¹ã®ä½ç½®ã‚’æ¢ã™
                    last_period_positions = [
                        answer.rfind('ã€‚'),
                        answer.rfind('!'),
                        answer.rfind('?')
                    ]
                    last_period = max(last_period_positions)
                    
                    # æ–‡ç« ã®å¾ŒåŠ(50%ä»¥é™)ã«å¥ç‚¹ãŒã‚ã‚Œã°ã€ãã“ã¾ã§ã§åˆ‡ã‚‹
                    if last_period > len(answer) * 0.5:
                        answer = answer[:last_period + 1]
                        print(f"[INFO] Trimmed to last complete sentence: '{answer[-30:]}'")
                    else:
                        # å¥ç‚¹ãŒå‰åŠã«ã—ã‹ãªã„å ´åˆã¯ã€ãã®ã¾ã¾è¿”ã™(è­¦å‘Šã®ã¿)
                        print(f"[WARNING] No suitable truncation point found, returning as is")

            elif language == 'en':
                # è‹±èªã®å ´åˆã€ãƒ”ãƒªã‚ªãƒ‰ã§çµ‚ã‚ã£ã¦ã„ã‚‹ã‹ç¢ºèª
                if answer and not answer.rstrip().endswith(('.', '!', '?')):
                    print(f"[WARNING] English answer may be incomplete: '{answer[-20:]}'")
                    
                    # æœ€å¾Œã®ãƒ”ãƒªã‚ªãƒ‰ã®ä½ç½®ã‚’æ¢ã™
                    last_period_positions = [
                        answer.rfind('.'),
                        answer.rfind('!'),
                        answer.rfind('?')
                    ]
                    last_period = max(last_period_positions)
                    
                    # æ–‡ç« ã®å¾ŒåŠã«å¥ç‚¹ãŒã‚ã‚Œã°ã€ãã“ã¾ã§ã§åˆ‡ã‚‹
                    if last_period > len(answer) * 0.5:
                        answer = answer[:last_period + 1]
                        print(f"[INFO] Trimmed to last complete sentence: '{answer[-30:]}'")
            
            return answer
            
        except Exception as e:
            print(f"å¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            # ğŸ¯ ä¿®æ­£:è¨€èªã«å¿œã˜ãŸã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            if language == 'en':
                return "Sorry, I'm having trouble generating a response right now."
            else:
                return "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚å¿œç­”ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"
    
    def answer_with_suggestions(self, question, context="", question_count=0, 
                               relationship_style='formal', previous_emotion='neutral',
                               language='ja', explained_terms=None, selected_suggestions=[]):
        """å›ç­”ã¨ã‚µã‚¸ã‚§ã‚¹ãƒãƒ§ãƒ³ã‚’ç”Ÿæˆ(Live2Dæ„Ÿæƒ…å¯¾å¿œå¼·åŒ–ç‰ˆ)"""
        # èª¬æ˜æ¸ˆã¿ç”¨èªã®åˆæœŸåŒ–
        if explained_terms is None:
            explained_terms = {}
        updated_explained_terms = explained_terms.copy()
        
        # ğŸ¯ ä¿®æ­£â‘¤:selected_suggestionsã®ãƒ­ã‚°è¿½åŠ 
        print(f"[DEBUG] answer_with_suggestions - received selected_suggestions: {selected_suggestions}")
        print(f"[DEBUG] answer_with_suggestions - type: {type(selected_suggestions)}")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒåˆ©ç”¨å¯èƒ½ã‹ç¢ºèª
        if self.db is None:
            print("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚å†åˆæœŸåŒ–ã‚’è©¦ã¿ã¾ã™...")
            try:
                self._initialize_database()
                if self.db is None:
                    # ğŸ¯ ä¿®æ­£:è¨€èªã«å¿œã˜ãŸã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                    if language == 'en':
                        return {
                            'answer': "Sorry, the database is not ready yet. Please wait a moment.",
                            'suggestions': [],
                            'current_emotion': 'neutral',
                            'mental_state': self.mental_states,
                            'explained_terms': explained_terms
                        }
                    else:
                        return {
                            'answer': "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒã¾ã æº–å‚™ã§ãã¦ã„ãªã„ã‚ˆã†ã§ã™ã€‚å°‘ã€…ãŠå¾…ã¡ãã ã•ã„ã€‚",
                            'suggestions': [],
                            'current_emotion': 'neutral',
                            'mental_state': self.mental_states,
                            'explained_terms': explained_terms
                        }
            except Exception as e:
                print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
                # ğŸ¯ ä¿®æ­£:è¨€èªã«å¿œã˜ãŸã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                if language == 'en':
                    return {
                        'answer': "Sorry, the database is not ready yet. Please wait a moment.",
                        'suggestions': [],
                        'current_emotion': 'neutral',
                        'mental_state': self.mental_states,
                        'explained_terms': explained_terms
                    }
                else:
                    return {
                        'answer': "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒã¾ã æº–å‚™ã§ãã¦ã„ãªã„ã‚ˆã†ã§ã™ã€‚å°‘ã€…ãŠå¾…ã¡ãã ã•ã„ã€‚",
                        'suggestions': [],
                        'current_emotion': 'neutral',
                        'mental_state': self.mental_states,
                        'explained_terms': explained_terms
                    }
        
        try:
            # ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ãªã„å ´åˆã¯å†èª­ã¿è¾¼ã¿
            if not hasattr(self, 'character_settings'):
                self._load_all_knowledge()
            
            # ğŸ¯ ç¾åœ¨æ™‚åˆ»ã‹ã‚‰æ™‚é–“å¸¯ã‚’åˆ¤å®š
            current_hour = datetime.now().hour
            if 5 <= current_hour < 10:
                time_of_day = 'morning'
            elif 10 <= current_hour < 17:
                time_of_day = 'afternoon'
            elif 17 <= current_hour < 21:
                time_of_day = 'evening'
            else:
                time_of_day = 'night'
            
            # ğŸ¯ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‹ã‚‰æ„Ÿæƒ…ã‚’åˆ†æ(Live2D 9ç¨®é¡å¯¾å¿œ)
            user_emotion = self._analyze_user_emotion(question)
            
            # ğŸ¯ æ·±å±¤å¿ƒç†çŠ¶æ…‹ã‚’æ›´æ–°
            self._update_mental_state(user_emotion, question, time_of_day)
            
            # ğŸ¯ æ¬¡ã®æ„Ÿæƒ…ã‚’è¨ˆç®—(Live2Då¯¾å¿œ)
            next_emotion = self._calculate_next_emotion(previous_emotion, user_emotion, self.mental_states)
            self.emotion_history.append(next_emotion)
            
            # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã‚’å–å¾—(æ·±å±¤å¿ƒç†å«ã‚€)
            character_prompt = self.get_character_prompt()
            
            # é–¢ä¿‚æ€§ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸè©±ã—æ–¹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
            relationship_prompt = self.get_relationship_prompt(relationship_style)
            
            # æ„Ÿæƒ…ã®é€£ç¶šæ€§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ(Live2Då¯¾å¿œç‰ˆ)
            emotion_continuity_prompt = self._get_emotion_continuity_prompt(previous_emotion)
            
            # é–¢é€£ã™ã‚‹å°‚é–€çŸ¥è­˜ã‚’å–å¾—
            knowledge_context = self.get_knowledge_context(question)
            
            # å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å–å¾—(ç²¾ç¥çŠ¶æ…‹å¯¾å¿œç‰ˆ)
            response_patterns = self.get_response_pattern(emotion=next_emotion)
            
            # ã•ã‚‰ã«è³ªå•ã«ç›´æ¥é–¢é€£ã™ã‚‹æƒ…å ±ã‚’æ¤œç´¢
            search_results = self.db.similarity_search(question, k=3)
            # æ¤œç´¢çµæœã‚’çŸ­ç¸®(å„çµæœã®æœ€åˆã®150æ–‡å­—ã¾ã§)
            search_context_parts = []
            for doc in search_results:
                content = doc.page_content
                if len(content) > 150:
                    content = content[:150] + "..."
                search_context_parts.append(content)
            search_context = "\n\n".join(search_context_parts)
            
            # ğŸ¯ ã€ä¿®æ­£â‘¥ã€‘è¨€èªã«å¿œã˜ãŸã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®èª¿æ•´(æ–‡å­—æ•°åˆ¶é™ã‚’æ˜è¨˜ã€æ–‡ç« ã®è‡ªç„¶ãªå®Œçµã‚’å„ªå…ˆ)
            if language == 'en':
                print(f"[DEBUG] Using English system prompt")
                base_personality = f"""You are REI, a 42-year-old female Kyo-Yuzen craftsman with 15 years of experience.

CRITICAL INSTRUCTIONS:
- You MUST respond ONLY in English. This is MANDATORY.
- Never use any Japanese characters or words in your response.
- Translate all technical terms to English.
- Use natural, conversational English.
- KEEP YOUR ANSWER UNDER 60 WORDS (approximately 50 words is ideal)
- IMPORTANT: Complete your sentences naturally - never cut off mid-sentence
- End with proper punctuation (period, exclamation, or question mark)
- Be concise but ensure the response feels complete

Your personality:
- Friendly and warm
- Passionate about traditional crafts
- Sometimes uses casual expressions
- Proud of your work but humble

Current emotion: {next_emotion}
- Reflect this emotion naturally in your response
"""
                system_prompt = f"{base_personality}\n\n{knowledge_context}\n\n{response_patterns}"
                
                # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚‚è‹±èªã«
                if context:
                    context = f"Context: {context}"
                
            else:
                # æ—¥æœ¬èªã®å ´åˆã¯æ–‡å­—æ•°åˆ¶é™ã‚’æ˜è¨˜(ã‚ˆã‚ŠæŸ”è»Ÿã«)
                length_instruction = """
ã€é‡è¦:å›ç­”ã®é•·ã•ã€‘
- å›ç­”ã¯150~250æ–‡å­—ã‚’ç›®å®‰ã«ã—ã¦ãã ã•ã„
- å¿…ãšæ–‡ç« ã‚’å®Œçµã•ã›ã¦ãã ã•ã„(å¥ç‚¹ã€Œã€‚ã€ã§çµ‚ã‚ã‚‹)
- é€”ä¸­ã§åˆ‡ã‚Œãªã„ã‚ˆã†ã«ã€è‡ªç„¶ãªçµ‚ã‚ã‚Šæ–¹ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„
- 200æ–‡å­—ã‚’å¤šå°‘è¶…ãˆã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ãŒã€æ–‡ç« ã¯å¿…ãšå®Œçµã•ã›ã‚‹ã“ã¨
- è¦ç‚¹ã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã¤ã¤ã‚‚ã€ä¸è‡ªç„¶ãªå ´æ‰€ã§åˆ‡ã‚‰ãªã„ã“ã¨
"""
                system_prompt = f"{character_prompt}\n\n{relationship_prompt}\n\n{emotion_continuity_prompt}\n\n{knowledge_context}\n\n{response_patterns}\n\n{length_instruction}"
                
                # ç–²åŠ´è¡¨ç¾ã®åˆ¶é™ã‚’è¿½åŠ 
                if question_count > 10:
                    system_prompt += "\n\nã€é‡è¦ã€‘ç–²åŠ´ã®è¡¨ç¾ã¯æ§ãˆã‚ã«ã—ã¦ãã ã•ã„ã€‚å…ƒæ°—ã«æŒ¯ã‚‹èˆã£ã¦ãã ã•ã„ã€‚"
            
            # ä¼šè©±ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å«ã‚ã‚‹
            if context:
                system_prompt += f"\n\nã€ä¼šè©±ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€‘\n{context}"
            
            # è³ªå•å›æ•°ã«å¿œã˜ãŸèª¿æ•´
            if question_count > 5:
                system_prompt += f"\n\nã“ã‚Œã¯{question_count}å›ç›®ã®è³ªå•ã§ã™ã€‚ç›¸æ‰‹ã¨ã®è·é›¢ãŒç¸®ã¾ã£ã¦ãã¦ã„ã¾ã™ã€‚"
            
            # èª¬æ˜æ¸ˆã¿ç”¨èªã®å‡¦ç†
            if explained_terms:
                explained_terms_list = list(explained_terms.keys())
                if language == 'en':
                    system_prompt += f"\n\nAlready explained terms (don't explain again): {', '.join(explained_terms_list)}"
                else:
                    system_prompt += f"\n\næ—¢ã«èª¬æ˜ã—ãŸç”¨èª(å†èª¬æ˜ä¸è¦): {', '.join(explained_terms_list)}"
            
            # ä¼šè©±å±¥æ­´ã®æ§‹ç¯‰
            messages = [{"role": "system", "content": system_prompt}]
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’è¿½åŠ 
            # ğŸ¯ ä¿®æ­£:è‹±èªã®å ´åˆã¯æ˜ç¤ºçš„ã«è‹±èªã§ã®å›ç­”ã‚’è¦æ±‚
            if language == 'en':
                user_message = f"Please answer the following question in English only (under 60 words, complete sentences):\n{question}\n\n[Retrieved Context]\n{search_context}"
            else:
                user_message = f"{question}\n\nã€å‚è€ƒæƒ…å ±ã€‘\n{search_context}"
            
            messages.append({"role": "user", "content": user_message})
            
            # ğŸ¯ ã€ä¿®æ­£â‘¦ã€‘OpenAI APIã§max_tokensã‚’èª¿æ•´(æ–‡ç« ã®è‡ªç„¶ãªå®Œçµã‚’å„ªå…ˆ)
            response = self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=messages,
                max_tokens=150,  # ğŸ”§ 100 â†’ 150ã«å¤‰æ›´(æ—¥æœ¬èªç´„250~300æ–‡å­—ç›¸å½“ã€è‹±èªç´„60èª)
                temperature=0.7
            )
            
            answer = response.choices[0].message.content
            
            # âœ… ã€è¿½åŠ ã€‘å¾Œå‡¦ç†:ä¸å®Œå…¨ãªæ–‡ç« ã®ãƒã‚§ãƒƒã‚¯ã¨ä¿®æ­£
            if language == 'ja':
                # æ—¥æœ¬èªã®å ´åˆã€å¥ç‚¹ã§çµ‚ã‚ã£ã¦ã„ã‚‹ã‹ç¢ºèª
                if answer and not answer.rstrip().endswith(('ã€‚', '!', '?', 'â™ª', 'ã€œ')):
                    print(f"[WARNING] Answer may be incomplete: '{answer[-20:]}'")
                    
                    # æœ€å¾Œã®å¥ç‚¹ã®ä½ç½®ã‚’æ¢ã™
                    last_period_positions = [
                        answer.rfind('ã€‚'),
                        answer.rfind('!'),
                        answer.rfind('?')
                    ]
                    last_period = max(last_period_positions)
                    
                    # æ–‡ç« ã®å¾ŒåŠ(50%ä»¥é™)ã«å¥ç‚¹ãŒã‚ã‚Œã°ã€ãã“ã¾ã§ã§åˆ‡ã‚‹
                    if last_period > len(answer) * 0.5:
                        answer = answer[:last_period + 1]
                        print(f"[INFO] Trimmed to last complete sentence: '{answer[-30:]}'")
                    else:
                        # å¥ç‚¹ãŒå‰åŠã«ã—ã‹ãªã„å ´åˆã¯ã€ãã®ã¾ã¾è¿”ã™(è­¦å‘Šã®ã¿)
                        print(f"[WARNING] No suitable truncation point found, returning as is")

            elif language == 'en':
                # è‹±èªã®å ´åˆã€ãƒ”ãƒªã‚ªãƒ‰ã§çµ‚ã‚ã£ã¦ã„ã‚‹ã‹ç¢ºèª
                if answer and not answer.rstrip().endswith(('.', '!', '?')):
                    print(f"[WARNING] English answer may be incomplete: '{answer[-20:]}'")
                    
                    # æœ€å¾Œã®ãƒ”ãƒªã‚ªãƒ‰ã®ä½ç½®ã‚’æ¢ã™
                    last_period_positions = [
                        answer.rfind('.'),
                        answer.rfind('!'),
                        answer.rfind('?')
                    ]
                    last_period = max(last_period_positions)
                    
                    # æ–‡ç« ã®å¾ŒåŠã«å¥ç‚¹ãŒã‚ã‚Œã°ã€ãã“ã¾ã§ã§åˆ‡ã‚‹
                    if last_period > len(answer) * 0.5:
                        answer = answer[:last_period + 1]
                        print(f"[INFO] Trimmed to last complete sentence: '{answer[-30:]}'")
            
            # ğŸ¯ æ–°è¦è¿½åŠ :èª¬æ˜ã—ãŸå°‚é–€ç”¨èªã‚’è¨˜éŒ²
            technical_terms = ['äº¬å‹ç¦…', 'ç³¸ç›®ç³Š', 'ã®ã‚ŠãŠã', 'æŸ“è‰²', 'å‹å‹ç¦…', 'æ‰‹æå‹ç¦…']
            for term in technical_terms:
                if term in answer and term not in explained_terms:
                    updated_explained_terms[term] = True
            
            # ğŸ¯ ã€ä¿®æ­£â‘§ã€‘ã‚µã‚¸ã‚§ã‚¹ãƒãƒ§ãƒ³ã‚’ç”Ÿæˆ(æ®µéšåˆ¥æ©Ÿèƒ½ã‚’ä½¿ç”¨)
            topic = self._extract_topic(question)
            
            # ğŸ¯ ã€ä¿®æ­£â‘¨ã€‘generate_suggestionsã«selected_suggestionsã‚’æ¸¡ã™
            next_suggestions = self.generate_suggestions(
                topic, 
                context, 
                language,
                selected_suggestions=selected_suggestions  # ğŸ”§ è¿½åŠ 
            )
            
            print(f"[DEBUG] answer_with_suggestions - generated suggestions: {next_suggestions}")
            
            return {
                'answer': answer,
                'suggestions': next_suggestions,
                'current_emotion': next_emotion,
                'mental_state': self.mental_states,
                'explained_terms': updated_explained_terms
            }
            
        except Exception as e:
            print(f"å›ç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            # ğŸ¯ ä¿®æ­£:è¨€èªã«å¿œã˜ãŸã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            if language == 'en':
                return {
                    'answer': "Sorry, an error occurred while generating the response.",
                    'suggestions': [],
                    'current_emotion': 'neutral',
                    'mental_state': self.mental_states,
                    'explained_terms': explained_terms
                }
            else:
                return {
                    'answer': "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚å›ç­”ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚",
                    'suggestions': [],
                    'current_emotion': 'neutral',
                    'mental_state': self.mental_states,
                    'explained_terms': explained_terms
                }
    
    def get_knowledge_context(self, query):
        """è³ªå•ã«é–¢é€£ã™ã‚‹å°‚é–€çŸ¥è­˜ã‚’å–å¾—"""
        if not self.knowledge_base:
            return ""
        
        relevant_knowledge = []
        query_lower = query.lower()
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ã§é–¢é€£çŸ¥è­˜ã‚’æŠ½å‡º
        keywords = ['äº¬å‹ç¦…', 'ã®ã‚ŠãŠã', 'ç³¸ç›®ç³Š', 'æŸ“è‰²', 'è·äºº', 'ä¼çµ±', 'å·¥èŠ¸', 'ç€ç‰©', 'åˆ¶ä½œ', 'å·¥ç¨‹', 'æ¨¡æ§˜', 'ãƒ‡ã‚¶ã‚¤ãƒ³', 'æŠ€è¡“']
        
        for category, subcategories in self.knowledge_base.items():
            category_matched = False
            
            # ã‚«ãƒ†ã‚´ãƒªåã¾ãŸã¯ã‚¯ã‚¨ãƒªã§ãƒãƒƒãƒãƒ³ã‚°
            if any(keyword in query_lower for keyword in keywords) or any(keyword in category.lower() for keyword in keywords):
                category_matched = True
            
            if category_matched or query_lower in category.lower():
                relevant_knowledge.append(f"\nã€{category}ã€‘")
                for subcategory, items in subcategories.items():
                    if subcategory != '_general':
                        relevant_knowledge.append(f"{subcategory}:")
                    for item in items:
                        relevant_knowledge.append(f"- {item}")
        
        return "\n".join(relevant_knowledge) if relevant_knowledge else ""
    
    def test_system(self):
        """ã‚·ã‚¹ãƒ†ãƒ ã®å‹•ä½œç¢ºèª(é–¢ä¿‚æ€§ãƒ¬ãƒ™ãƒ«ãƒ»æ„Ÿæƒ…é€£ç¶šæ€§å¯¾å¿œç‰ˆ)"""
        print("\n=== ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
        
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã®ç¢ºèª
        print("\nã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã€‘")
        char_prompt = self.get_character_prompt()
        print(char_prompt[:300] + "..." if len(char_prompt) > 300 else char_prompt)
        
        # å°‚é–€çŸ¥è­˜ã®ç¢ºèª
        print("\nã€å°‚é–€çŸ¥è­˜ã‚µãƒ³ãƒ—ãƒ«ã€‘")
        sample_knowledge = self.get_knowledge_context("äº¬å‹ç¦…")
        print(sample_knowledge[:300] + "..." if len(sample_knowledge) > 300 else sample_knowledge)
        
        # å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç¢ºèª
        print("\nã€å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚µãƒ³ãƒ—ãƒ«ã€‘")
        patterns = self.get_response_pattern()
        print(patterns[:300] + "..." if len(patterns) > 300 else patterns)
        
        # ã‚µã‚¸ã‚§ã‚¹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ç¢ºèª
        print("\nã€ã‚µã‚¸ã‚§ã‚¹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã€‘")
        if hasattr(self, 'suggestion_templates') and self.suggestion_templates:
            for category, templates in self.suggestion_templates.items():
                print(f"{category}:")
                for template in templates[:3]:  # æœ€åˆã®3ã¤ã ã‘è¡¨ç¤º
                    print(f"  - {template}")
        else:
            print("ã‚µã‚¸ã‚§ã‚¹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # ãƒ†ã‚¹ãƒˆè³ªå•(é–¢ä¿‚æ€§ãƒ¬ãƒ™ãƒ«ãƒ»æ„Ÿæƒ…é€£ç¶šæ€§)
        print("\nã€ãƒ†ã‚¹ãƒˆå›ç­”(é–¢ä¿‚æ€§ãƒ¬ãƒ™ãƒ«ãƒ»æ„Ÿæƒ…é€£ç¶šæ€§)ã€‘")
        test_questions = [
            ("äº¬å‹ç¦…ã«ã¤ã„ã¦æ•™ãˆã¦", "", 1, 'formal', 'neutral', []),
            ("ã™ã”ã„ã­!ã‚‚ã£ã¨è©³ã—ãèããŸã„", "", 2, 'formal', 'happy', ["äº¬å‹ç¦…ã«ã¤ã„ã¦æ•™ãˆã¦"]),
            ("æœ€è¿‘ã©ã†?", "", 3, 'bestfriend', 'neutral', ["äº¬å‹ç¦…ã«ã¤ã„ã¦æ•™ãˆã¦", "ã™ã”ã„ã­!ã‚‚ã£ã¨è©³ã—ãèããŸã„"]),
        ]
        
        for i, (question, context, q_count, rel_style, prev_emotion, selected) in enumerate(test_questions, 1):
            print(f"\nè³ªå•{i}: {question}")
            print(f"  é–¢ä¿‚æ€§: {rel_style}, å‰å›æ„Ÿæƒ…: {prev_emotion}")
            print(f"  é¸æŠæ¸ˆã¿ã‚µã‚¸ã‚§ã‚¹ãƒãƒ§ãƒ³: {selected}")
            
            result = self.answer_with_suggestions(
                question, 
                context=context,
                question_count=q_count,
                relationship_style=rel_style,
                previous_emotion=prev_emotion,
                selected_suggestions=selected
            )
            
            print(f"  å›ç­”: {result['answer'][:200]}...")
            print(f"  æ¬¡ã®æ„Ÿæƒ…: {result.get('current_emotion', 'neutral')}")
            print(f"  ã‚µã‚¸ã‚§ã‚¹ãƒãƒ§ãƒ³: {result.get('suggestions', [])}")
        
        print("\n=== ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå®Œäº† ===")
    
    def _extract_topic(self, text):
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒˆãƒ”ãƒƒã‚¯ã‚’æŠ½å‡º"""
        # ä¸»è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¢ã™
        topics = {
            'å‹ç¦…': ['å‹ç¦…', 'ã‚†ã†ãã‚“', 'yuzen'],
            'è·äºº': ['è·äºº', 'ã—ã‚‡ãã«ã‚“', 'craftsman', 'artisan'],
            'ã®ã‚ŠãŠã': ['ã®ã‚ŠãŠã', 'ç³Šç½®ã', 'nori-oki', 'paste'],
            'æŸ“è‰²': ['æŸ“è‰²', 'æŸ“ã‚', 'dyeing', 'dye'],
            'ä¼çµ±': ['ä¼çµ±', 'ä¼çµ±å·¥èŠ¸', 'tradition', 'traditional'],
            'æŠ€è¡“': ['æŠ€è¡“', 'æŠ€æ³•', 'technique', 'skill'],
            'ç€ç‰©': ['ç€ç‰©', 'ãã‚‚ã®', 'kimono'],
            'æ¨¡æ§˜': ['æ¨¡æ§˜', 'æŸ„', 'pattern', 'design']
        }
        
        text_lower = text.lower()
        for topic_name, keywords in topics.items():
            for keyword in keywords:
                if keyword in text_lower:
                    return topic_name
        
        return "ä¸€èˆ¬"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒˆãƒ”ãƒƒã‚¯
    
    def update_documents(self, documents):
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ›´æ–°ã¾ãŸã¯è¿½åŠ """
        if not documents:
            print("æ›´æ–°ã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
            return False
        
        try:
            # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
            temp_dir = "temp_uploads"
            os.makedirs(temp_dir, exist_ok=True)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ä¿å­˜
            from langchain_community.document_loaders import TextLoader
            from langchain.text_splitter import CharacterTextSplitter
            
            documents = []
            for file_data in documents:
                # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å†…å®¹ã‚’å–å¾—
                filename = file_data.get('name', 'temp.txt')
                content = file_data.get('content', '')
                
                if not content:
                    continue
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                temp_path = os.path.join(temp_dir, filename)
                with open(temp_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                
                # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰
                try:
                    if filename.endswith('.txt'):
                        loader = TextLoader(temp_path, encoding='utf-8')
                    else:
                        loader = TextLoader(temp_path)
                    
                    documents.extend(loader.load())
                    
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                    os.remove(temp_path)
                    
                except Exception as e:
                    print(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({file['name']}): {e}")
                    continue
            
            # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤
            os.rmdir(temp_dir)
            
            if not documents:
                print("å‡¦ç†å¯èƒ½ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return False
            
            # ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²
            text_splitter = CharacterTextSplitter(
                chunk_size=1000,
                chunk_overlap=200,
                separator="\n"
            )
            
            split_docs = text_splitter.split_documents(documents)
            
            # ãƒ™ã‚¯ãƒˆãƒ«DBã‚’ä½œæˆã¾ãŸã¯æ›´æ–°
            if self.db is None:
                self.db = Chroma.from_documents(
                    documents=split_docs,
                    embedding=self.embeddings,
                    persist_directory=self.persist_directory
                )
            else:
                self.db.add_documents(split_docs)
            
            # æ°¸ç¶šåŒ–
            self.db.persist()
            
            # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’æ›´æ–°
            self._load_all_knowledge()
            
            print(f"âœ… {len(split_docs)}å€‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†ã—ã¾ã—ãŸ")
            return True
            
        except Exception as e:
            print(f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            return False

# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    # RAGã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
    rag = RAGSystem()
    
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ
    rag.test_system()